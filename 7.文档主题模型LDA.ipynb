{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim import corpora, models, similarities\n",
    "import jieba\n",
    "import lda\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopword():\n",
    "    f_stop = open('stopword.txt')\n",
    "    sw = [line.strip() for line in f_stop]\n",
    "    f_stop.close()\n",
    "    return sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始化停止词列表 --\n",
      "开始读入语料数据 -- \n",
      "读入语料数据完成，用时13.506秒\n",
      "文本数目：2043个\n",
      "正在建立词典 --\n",
      "词的个数： 63871\n",
      "正在计算文本向量 --\n",
      "正在计算文档TF-IDF --\n",
      "建立文档TF-IDF完成，用时0.272秒\n",
      "LDA模型拟合推断 --\n",
      "LDA模型完成，训练时间为\t7.542秒\n",
      "10个文档的主题分布：\n",
      "topic = \t [[0.00000000e+00 1.96805992e-03]\n",
      " [1.00000000e+00 3.23084086e-01]\n",
      " [2.00000000e+00 1.96805992e-03]\n",
      " [3.00000000e+00 5.10830939e-01]\n",
      " [4.00000000e+00 1.96805992e-03]\n",
      " [5.00000000e+00 1.96805992e-03]\n",
      " [6.00000000e+00 1.96805992e-03]\n",
      " [7.00000000e+00 1.52308598e-01]\n",
      " [8.00000000e+00 1.96805992e-03]\n",
      " [9.00000000e+00 1.96805992e-03]]\n",
      "第601个文档的前10个主题： [3 1 7 9 8 6 5 4 2 0]\n",
      "[0.51083094 0.32308409 0.1523086  0.00196806 0.00196806 0.00196806\n",
      " 0.00196806 0.00196806 0.00196806 0.00196806]\n",
      "topic = \t [[0.00000000e+00 1.92962878e-03]\n",
      " [1.00000000e+00 3.99934411e-01]\n",
      " [2.00000000e+00 7.76924491e-02]\n",
      " [3.00000000e+00 1.92962878e-03]\n",
      " [4.00000000e+00 1.92962878e-03]\n",
      " [5.00000000e+00 4.51218300e-02]\n",
      " [6.00000000e+00 1.92962878e-03]\n",
      " [7.00000000e+00 4.65673536e-01]\n",
      " [8.00000000e+00 1.92962878e-03]\n",
      " [9.00000000e+00 1.92962878e-03]]\n",
      "第248个文档的前10个主题： [7 1 2 5 9 8 6 4 3 0]\n",
      "[0.46567354 0.39993441 0.07769245 0.04512183 0.00192963 0.00192963\n",
      " 0.00192963 0.00192963 0.00192963 0.00192963]\n",
      "topic = \t [[0.00000000e+00 4.33709892e-03]\n",
      " [1.00000000e+00 4.90783513e-01]\n",
      " [2.00000000e+00 4.33709892e-03]\n",
      " [3.00000000e+00 4.33709892e-03]\n",
      " [4.00000000e+00 4.33709892e-03]\n",
      " [5.00000000e+00 4.33709892e-03]\n",
      " [6.00000000e+00 4.33709892e-03]\n",
      " [7.00000000e+00 4.74519730e-01]\n",
      " [8.00000000e+00 4.33709892e-03]\n",
      " [9.00000000e+00 4.33709892e-03]]\n",
      "第1657个文档的前10个主题： [1 7 9 8 6 5 4 3 2 0]\n",
      "[0.49078351 0.47451973 0.0043371  0.0043371  0.0043371  0.0043371\n",
      " 0.0043371  0.0043371  0.0043371  0.0043371 ]\n",
      "topic = \t [[0.00000000e+00 2.62679067e-03]\n",
      " [1.00000000e+00 3.98925006e-01]\n",
      " [2.00000000e+00 1.84399024e-01]\n",
      " [3.00000000e+00 8.25654343e-02]\n",
      " [4.00000000e+00 2.62679067e-03]\n",
      " [5.00000000e+00 1.24914028e-01]\n",
      " [6.00000000e+00 2.62679067e-03]\n",
      " [7.00000000e+00 1.96062520e-01]\n",
      " [8.00000000e+00 2.62679067e-03]\n",
      " [9.00000000e+00 2.62679067e-03]]\n",
      "第1845个文档的前10个主题： [1 7 2 5 3 9 8 6 4 0]\n",
      "[0.39892501 0.19606252 0.18439902 0.12491403 0.08256543 0.00262679\n",
      " 0.00262679 0.00262679 0.00262679 0.00262679]\n",
      "topic = \t [[0.00000000e+00 3.86477029e-03]\n",
      " [1.00000000e+00 4.82932895e-01]\n",
      " [2.00000000e+00 2.99948126e-01]\n",
      " [3.00000000e+00 3.86477029e-03]\n",
      " [4.00000000e+00 3.86477029e-03]\n",
      " [5.00000000e+00 3.86477029e-03]\n",
      " [6.00000000e+00 3.86477029e-03]\n",
      " [7.00000000e+00 1.90065563e-01]\n",
      " [8.00000000e+00 3.86477029e-03]\n",
      " [9.00000000e+00 3.86477029e-03]]\n",
      "第1010个文档的前10个主题： [1 2 7 9 8 6 5 4 3 0]\n",
      "[0.4829329  0.29994813 0.19006556 0.00386477 0.00386477 0.00386477\n",
      " 0.00386477 0.00386477 0.00386477 0.00386477]\n",
      "topic = \t [[0.00000000e+00 2.18258495e-03]\n",
      " [1.00000000e+00 1.80073962e-01]\n",
      " [2.00000000e+00 5.96093416e-01]\n",
      " [3.00000000e+00 2.18258495e-03]\n",
      " [4.00000000e+00 2.18258495e-03]\n",
      " [5.00000000e+00 2.18258495e-03]\n",
      " [6.00000000e+00 2.18258495e-03]\n",
      " [7.00000000e+00 2.08554536e-01]\n",
      " [8.00000000e+00 2.18258495e-03]\n",
      " [9.00000000e+00 2.18258495e-03]]\n",
      "第1527个文档的前10个主题： [2 7 1 9 8 6 5 4 3 0]\n",
      "[0.59609342 0.20855454 0.18007396 0.00218258 0.00218258 0.00218258\n",
      " 0.00218258 0.00218258 0.00218258 0.00218258]\n",
      "topic = \t [[0.00000000e+00 1.32358423e-03]\n",
      " [1.00000000e+00 2.91340351e-01]\n",
      " [2.00000000e+00 1.87189743e-01]\n",
      " [3.00000000e+00 1.32358423e-03]\n",
      " [4.00000000e+00 1.32358423e-03]\n",
      " [5.00000000e+00 2.23083049e-01]\n",
      " [6.00000000e+00 1.32358423e-03]\n",
      " [7.00000000e+00 2.90445328e-01]\n",
      " [8.00000000e+00 1.32358423e-03]\n",
      " [9.00000000e+00 1.32358423e-03]]\n",
      "第1437个文档的前10个主题： [1 7 5 2 9 8 6 4 3 0]\n",
      "[0.29134035 0.29044533 0.22308305 0.18718974 0.00132358 0.00132358\n",
      " 0.00132358 0.00132358 0.00132358 0.00132358]\n",
      "topic = \t [[0.00000000e+00 4.26635239e-03]\n",
      " [1.00000000e+00 3.68794948e-01]\n",
      " [2.00000000e+00 2.25333259e-01]\n",
      " [3.00000000e+00 4.26635239e-03]\n",
      " [4.00000000e+00 4.26635239e-03]\n",
      " [5.00000000e+00 4.26635239e-03]\n",
      " [6.00000000e+00 4.26635239e-03]\n",
      " [7.00000000e+00 3.76007348e-01]\n",
      " [8.00000000e+00 4.26635239e-03]\n",
      " [9.00000000e+00 4.26635239e-03]]\n",
      "第1289个文档的前10个主题： [7 1 2 9 8 6 5 4 3 0]\n",
      "[0.37600735 0.36879495 0.22533326 0.00426635 0.00426635 0.00426635\n",
      " 0.00426635 0.00426635 0.00426635 0.00426635]\n",
      "topic = \t [[0.00000000e+00 1.03649706e-01]\n",
      " [1.00000000e+00 4.14127290e-01]\n",
      " [2.00000000e+00 4.21761861e-03]\n",
      " [3.00000000e+00 1.23395137e-01]\n",
      " [4.00000000e+00 4.21761861e-03]\n",
      " [5.00000000e+00 4.21761861e-03]\n",
      " [6.00000000e+00 4.21761861e-03]\n",
      " [7.00000000e+00 3.33522201e-01]\n",
      " [8.00000000e+00 4.21761861e-03]\n",
      " [9.00000000e+00 4.21761861e-03]]\n",
      "第559个文档的前10个主题： [1 7 3 0 9 8 6 5 4 2]\n",
      "[0.41412729 0.3335222  0.12339514 0.10364971 0.00421762 0.00421762\n",
      " 0.00421762 0.00421762 0.00421762 0.00421762]\n",
      "topic = \t [[0.00000000e+00 5.48589945e-01]\n",
      " [1.00000000e+00 1.47662058e-01]\n",
      " [2.00000000e+00 9.28702950e-02]\n",
      " [3.00000000e+00 8.19934309e-02]\n",
      " [4.00000000e+00 1.94548198e-03]\n",
      " [5.00000000e+00 1.94548198e-03]\n",
      " [6.00000000e+00 1.94548198e-03]\n",
      " [7.00000000e+00 1.19156823e-01]\n",
      " [8.00000000e+00 1.94548198e-03]\n",
      " [9.00000000e+00 1.94548198e-03]]\n",
      "第563个文档的前10个主题： [0 1 7 2 3 9 8 6 5 4]\n",
      "[0.54858994 0.14766206 0.11915682 0.0928703  0.08199343 0.00194548\n",
      " 0.00194548 0.00194548 0.00194548 0.00194548]\n",
      "每个主题的词分布：\n",
      "主题#0：\t\n",
      "词：\t 督察 环保 仲裁 督察组 越南 领土 总理 \n",
      "主题#1：\t\n",
      "词：\t 日本 阅读 美国 总统 公司 孩子 政府 \n",
      "主题#2：\t\n",
      "词：\t 朝鲜 发展 经济 改革 中国 投资 医疗 \n",
      "主题#3：\t\n",
      "词：\t 台湾 回答 创新 结婚 大陆 蔡 保护 \n",
      "主题#4：\t\n",
      "词：\t 女士 尸检 百度 行人 欧元 用户 搜索 \n",
      "主题#5：\t\n",
      "词：\t 希拉里 罗 右肾 尔特 杜特 选民 巴西 \n",
      "主题#6：\t\n",
      "词：\t 雷洋 李某 林 灾害 搜救 遗体 福建 \n",
      "主题#7：\t\n",
      "词：\t 医院 警方 男子 学生 民警 患者 人 \n",
      "主题#8：\t\n",
      "词：\t 特朗普 候选人 共和党 穆斯林 欧盟 大选 英国 \n",
      "主题#9：\t\n",
      "词：\t 陈某 张某 天气 广西 捅 大风 降雨 \n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "print('初始化停止词列表 --')\n",
    "t_start = time.time()\n",
    "stop_words = load_stopword()\n",
    "\n",
    "print('开始读入语料数据 -- ')\n",
    "f = open('news.dat', encoding='utf-8')    #LDA_test.txt\n",
    "texts = [[word for word in line.strip().lower().split() if word not in stop_words] for line in f]\n",
    "# texts = [line.strip().split() for line in f]\n",
    "print('读入语料数据完成，用时%.3f秒' % (time.time() - t_start))\n",
    "f.close()\n",
    "M = len(texts)\n",
    "print('文本数目：%d个' % M)\n",
    "# pprint(texts)\n",
    "\n",
    "print('正在建立词典 --')\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "V = len(dictionary)\n",
    "print('词的个数：', V)\n",
    "print('正在计算文本向量 --')\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "print('正在计算文档TF-IDF --')\n",
    "t_start = time.time()\n",
    "corpus_tfidf = models.TfidfModel(corpus)[corpus]\n",
    "print('建立文档TF-IDF完成，用时%.3f秒' % (time.time() - t_start))\n",
    "print('LDA模型拟合推断 --')\n",
    "num_topics = 10\n",
    "t_start = time.time()\n",
    "lda = models.LdaModel(corpus_tfidf, num_topics=num_topics, id2word=dictionary,\n",
    "    alpha=0.01, eta=0.01, minimum_probability=0.001,\n",
    "    update_every = 1, chunksize = 100, passes = 1)\n",
    "print('LDA模型完成，训练时间为\\t%.3f秒' % (time.time() - t_start))\n",
    "# 所有文档的主题\n",
    "# 随机打印某10个文档的主题\n",
    "num_show_topic = 10  # 每个文档显示前几个主题\n",
    "print('10个文档的主题分布：')\n",
    "doc_topics = lda.get_document_topics(corpus_tfidf)  # 所有文档的主题分布\n",
    "idx = np.arange(M)\n",
    "np.random.shuffle(idx)\n",
    "idx = idx[:10]\n",
    "for i in idx:\n",
    "    topic = np.array(doc_topics[i])\n",
    "    print('topic = \\t', topic)\n",
    "    topic_distribute = np.array(topic[:, 1])\n",
    "    # print topic_distribute\n",
    "    topic_idx = topic_distribute.argsort()[:-num_show_topic-1:-1]\n",
    "    print(('第%d个文档的前%d个主题：' % (i, num_show_topic)), topic_idx)\n",
    "    print(topic_distribute[topic_idx])\n",
    "num_show_term = 7   # 每个主题显示几个词\n",
    "print('每个主题的词分布：')\n",
    "for topic_id in range(num_topics):\n",
    "    print('主题#%d：\\t' % topic_id)\n",
    "    term_distribute_all = lda.get_topic_terms(topicid=topic_id)\n",
    "    term_distribute = term_distribute_all[:num_show_term]\n",
    "    term_distribute = np.array(term_distribute)\n",
    "    term_id = term_distribute[:, 0].astype(np.int)\n",
    "    print('词：\\t', end=' ')\n",
    "    for t in term_id:\n",
    "        print(dictionary.id2token[t], end=' ')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
